install.packages("stylo")
stylo()
library(stylo)
src<-paste(root,"data/metadata_export_collection14_20230705-06_27.csv",sep = "/")
#13266.HU-LX.metadata edit
#20230629(19.22)
################
library(readr)
library(stringi)
library(writexl)
root<-"~/Documents/GIT/HU-LX"
src<-paste(root,"data/metadata_export_collection14_20230705-06_27.csv",sep = "/")
d1<-read.csv(src)
root<-"~/Documents/Github/HU-LX"
src<-paste(root,"data/metadata_export_collection14_20230705-06_27.csv",sep = "/")
d1<-read.csv(src)
src<-paste(root,"meta/metadata_export_collection14_20230705-06_27.csv",sep = "/")
d1<-read.csv(src)
local<-"~/boxHKW/UNI/21S/DH/local/HU-LX"
src2<-paste(local,"metadata_export_collection14_20230705-06_27.csv.csv",sep = "/")
d3<-read.csv(src2,sep = ";",skip = 1)
src2<-paste(local,"meta/metadata_export_collection14_20230705-06_27.csv.csv",sep = "/")
d3<-read.csv(src2,sep = ";",skip = 1)
src2<-paste(local,"meta/metadata_export_collection14_20230705-06_27.csv",sep = "/")
d3<-read.csv(src2,sep = ";",skip = 1)
src2<-paste(local,"meta/metadata_export_collection14__20230705-06_27.csv",sep = "/")
d3<-read.csv(src2,sep = ";",skip = 1)
d3<-read.csv(src2,sep = ")
"~/boxHKW/UNI/21S/DH/local/HU-LX/meta"
d3<-read.csv(src2,sep = ",")
install.packages("SQL")
install.packages("sqliter")
install.packages("odbc")
install.packages("RSQL")
library(odbc)
con<-dbConnect(RSQLite::SQLite(),":memory")
con<-dbConnect(RSQLite::SQLite(),user="iosdbuser_01",password="getmeintothis00123",
host="212.227.12.122",port="3306",dbname="iosdb_001")
con
dbListTables(con)
View(con)
install.packages("RMariaDB")
con<-dbConnect(RMariaDB::MariaDB(),user="iosdbuser_01",password="getmeintothis00123",
host="212.227.12.122",port="3306",dbname="iosdb_001")
install.packages("DBI")
install.packages("DBI")
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
View(out)
View(out[[2]][[1]])
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
x
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/ponsapi.R", echo=TRUE)
baseurl<-url
baseurl<-url
baseurl<-url
#qurl<-"https://api.pons.com/v1/dictionary?q=schimmer&l=deen&ref=true"
url<-"https://api.pons.com/v1/dictionary"
#header:
cred<-read.csv("~/boxHKW/21S/DH/local/R/cred_gener.csv")
library(RCurl)
library(httr)
library(RCurl)
library(RCurl)
library(httr)
library(jsonlite)
library(curl)
#qurl<-"https://api.pons.com/v1/dictionary?q=schimmer&l=deen&ref=true"
url<-"https://api.pons.com/v1/dictionary"
#header:
cred<-read.csv("~/boxHKW/21S/DH/local/R/cred_gener.csv")
secret<-cred$key[cred$q=="pons"]
################
################
word<-"Padole"
lang<-"deen"
ref<-"true"
q<- paste0('{"q": ',word,'"l": "',lang,'"ref:" ',ref,'"}')
q<-paste0("?q=",word,"&l=",lang,"&ref=",ref)
q
askpons<-function(q){
baseurl<-url
#baseurl<-qurl
baseurl<-url
qurl<-paste0(baseurl,q)
comurl<-qurl
comurl
req<-httr::GET(comurl,httr::add_headers(
"X-Secret"=secret
))
x<-httr::content(req,"text")
if (x!="")
{out<-fromJSON(x)
#  lexikon
print(out[[2]][[1]][[3]][[2]][2])
print(out[[2]][[1]][[3]][[1]][2])
#translation
out[[2]][[1]][[3]][[2]][[4]][[1]][[2]][[1]]
out[[2]][[1]][[3]][[1]][[4]][[1]][[2]][[1]]
}
if(x=="")
cat("no results.")
return(x)
}
baseurl<-url
baseurl<-url
qurl<-paste0(baseurl,q)
comurl<-qurl
comurl
req<-httr::GET(comurl,httr::add_headers(
"X-Secret"=secret
))
x<-httr::content(req,"text")
if (x!="")
{out<-fromJSON(x)
#  lexikon
print(out[[2]][[1]][[3]][[2]][2])
print(out[[2]][[1]][[3]][[1]][2])
#translation
out[[2]][[1]][[3]][[2]][[4]][[1]][[2]][[1]]
out[[2]][[1]][[3]][[1]][[4]][[1]][[2]][[1]]
}
if(x=="")
cat("no results.")
resp<-askpons(q)
askpons<-function(q,word){
lang<-"deen"
ref<-"true"
q<- paste0('{"q": ',word,'"l": "',lang,'"ref:" ',ref,'"}')
q<-paste0("?q=",word,"&l=",lang,"&ref=",ref)
baseurl<-url
#baseurl<-qurl
baseurl<-url
qurl<-paste0(baseurl,q)
comurl<-qurl
comurl
req<-httr::GET(comurl,httr::add_headers(
"X-Secret"=secret
))
x<-httr::content(req,"text")
if (x!="")
{out<-fromJSON(x)
#  lexikon
print(out[[2]][[1]][[3]][[2]][2])
print(out[[2]][[1]][[3]][[1]][2])
#translation
out[[2]][[1]][[3]][[2]][[4]][[1]][[2]][[1]]
out[[2]][[1]][[3]][[1]][[4]][[1]][[2]][[1]]
}
if(x=="")
cat("no results.")
return(x)
}
resp<-askpons(q,"parole")
resp<-askpons(q,"Sprahe")
resp<-askpons(q,"sprichst")
askpons<-function(q,word){
lang<-"deen"
ref<-"true"
q<- paste0('{"q": ',word,'"l": "',lang,'"ref:" ',ref,'"}')
q<-paste0("?q=",word,"&l=",lang,"&ref=",ref)
baseurl<-url
#baseurl<-qurl
baseurl<-url
qurl<-paste0(baseurl,q)
comurl<-qurl
comurl
req<-httr::GET(comurl,httr::add_headers(
"X-Secret"=secret
))
x<-httr::content(req,"text")
if (x!="")
{out<-fromJSON(x)
#  lexikon
print(out[[2]][[1]][[3]][[2]][2])
print(out[[2]][[1]][[3]][[1]][2])
#translation
out[[2]][[1]][[3]][[2]][[4]][[1]][[2]][[1]]
out[[2]][[1]][[3]][[1]][[4]][[1]][[2]][[1]]
return(out)
}
if(x=="")
cat("no results.")
return(x)
}
askpons<-function(q,word){
lang<-"deen"
ref<-"true"
q<- paste0('{"q": ',word,'"l": "',lang,'"ref:" ',ref,'"}')
q<-paste0("?q=",word,"&l=",lang,"&ref=",ref)
baseurl<-url
#baseurl<-qurl
baseurl<-url
qurl<-paste0(baseurl,q)
comurl<-qurl
comurl
req<-httr::GET(comurl,httr::add_headers(
"X-Secret"=secret
))
x<-httr::content(req,"text")
if (x!="")
{out<-fromJSON(x)
#  lexikon
#     print(out[[2]][[1]][[3]][[2]][2])
#     print(out[[2]][[1]][[3]][[1]][2])
#
# #translation
#     out[[2]][[1]][[3]][[2]][[4]][[1]][[2]][[1]]
#     out[[2]][[1]][[3]][[1]][[4]][[1]][[2]][[1]]
return(out)
}
if(x=="")
cat("no results.")
return(x)
}
resp<-askpons(q,"sprichst")
View(resp)
View(resp[[2]][[1]])
resp$hits
resp<-askpons(q,"sprachest")
resp<-askpons(q,"sprachst")
getwd()
reticulate::repl_python()
url1<-"https://www.bing.com/search?q=guhl%2Fglaser%2Fbuch"
p<-xml_find_all(li,"div/p")
page<- read_html(url1)
url1<-"https://www.bing.com/search?q=14391.hkw.on.roof"
h2<-xml_find_all(li,"h2")
a<-xml_find_all(li,"div/a")
library(xml2)
getwd()
source("~/boxHKW/21S/DH/local/R/bingscr_notes.R", echo=TRUE)
url1<-"https://www.bing.com/search?q=potmaschin"
for(k in 1:length(h2)){
print(xml_text(h2[k]))
print(xml_text(a[k]))
print(xml_attr(a[k],"href"))
print(xml_text(p[k]))
}
source("~/boxHKW/21S/DH/local/R/bingscr_notes.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/bingscr_notes.R", echo=TRUE)
source("~/boxHKW/21S/DH/local/R/bingscr_notes.R", echo=TRUE)
setwd("~/Documents/GitHub/ETCRA5_dd23/R")
source("~/Documents/GitHub/ETCRA5_dd23/R/scripts/plotstats_simple_static.R", echo=TRUE)
src.h<-"samplenotebook.nb.html"
dta_t<-plot.stats(src.h,"ttr",10,T)
html.src=T
dta_t<-plot.stats(src.h,"ttr",10,html.src = T)
#dta<-tx.split(re,l.seg)
ifelse(html.src,dta<-re.html(src),dta<-re(src))
plot.stats<-function(src,out,seg,html.src){
re<-function(src){
x<-GET(src)
re<-content(x,"text")
dta<-tx.split(re,l.seg)
}
re.html<-function(src){
x<-read_html(src)
re<-xml_text(x)
dta<-tx.split(re,l.seg)
}
#dta<-re
get_types<-function(set,opt){
set$contentp<-gsub("[^A-Za-z0-9äöüß \n]","",set$content) #get clean text
set$contentp<-gsub("(\n)"," ",set$contentp) #get clean text
set$contentp<-gsub("(   )"," ",set$contentp) #get clean text
set$contentp<-gsub("(  )"," ",set$contentp) #get clean text
set$contentp<-gsub("^( )","",set$contentp) #get clean text
set$contentp<-gsub("(   )"," ",set$contentp) #get clean text
set$contentp<-gsub("(  )"," ",set$contentp) #get clean text
set$contentp<-gsub("^( )","",set$contentp) #get clean text
set$tokens<-stri_count_boundaries(set$contentp) # IMPORTANT: with type=word far too much!
wolftypes<-stri_split_boundaries(set$contentp)
types<-lapply(wolftypes,unique)
ltypes<-lapply(types,length)
wolfchars<-function(x) stri_count_boundaries(x,"character")
chars<-lapply(wolftypes, wolfchars)
chars.avg<-function(x)mean(x)
set$chars.avg<-lapply(chars,chars.avg)
set$types<-unlist(ltypes)
set$ttr<-set$types/set$tokens
return(set)
}
#########
#re[1:20] # dracor text one dim, to split into segments
tx.split<-function(text,l){
re.s<-stri_split_boundaries(text,simplify = T)
#re.s<-stri_split_regex(re,"\n",simplify = T) # split into sentences
re.s.start<-seq(1,length(re.s),l)
re.s.end<-seq(0,length(re.s),l)
content_df<-data.frame(id=1:length(re.s.start),content=NA)
for(k in 1:length(content_df$id)){
if (k<length(content_df$id)) {
segment<-re.s[re.s.start[k]:re.s.end[k+1]]
segment<-paste0(segment,collapse = " ")
content_df$content[k]<-segment
print(k)
}
if(k==length(re.s.start)){
segment.l<-re.s[re.s.start[k]:length(re.s)]
segment.l<-paste0(segment.l,collapse = " ")
content_df$content[k]<-segment.l
}
}
return(content_df)
}
######
l.seg<-100 # #segment length in words
l.seg<-seg
#dta<-tx.split(re,l.seg)
ifelse(html.src,dta<-re.html(src),dta<-re(src))
dta_t<-get_types(dta,1)
plot.out<-function(dta_t){
# scatter.smooth(1:length(dta_t$ttr),dta_t$ttr,.1,.1,type="h",
#                family = "gaussian",ylab="segment type/token ratio",xlab = paste0("segments of ",l.seg," words"),
#                col=2)
# scatter.smooth(1:length(dta_t$chars.avg),dta_t$chars.avg,.1,.1,type="h",
#                family = "gaussian",ylab="segment average word length / chars",xlab = paste0("segments of ",l.seg," words"),
#                col=2)
# if(out=="ttr")
#    scatter.smooth(1:length(dta_t$ttr),dta_t$ttr,.1,.1,type="h",
#                family = "gaussian",ylab="segment type/token ratio",main="type/token ratio",xlab = paste0("segments of ",l.seg," words"),
#                col=2)
# if(out=="char")
#    scatter.smooth(1:length(dta_t$chars.avg),dta_t$chars.avg,.1,.1,type="h",
#                family = "gaussian",ylab="segment average word length / chars",main="word length",xlab = paste0("segments of ",l.seg," words"),
#                col=2)
}
plot.out(dta_t)
return(dta_t)
# ttr.n<-get_transformed_values(unlist(dta_t$ttr))
# a2m<-max(dta_t$ttr)+.001
# a2im<-max(ttr.n)
# y<-max(a2im)/max(a2m)
# ttr.n<-ttr.n/y
# # scatter.smooth(1:length(ttr.n),ttr.n,.1,.1,type="h",
# #                family = "gaussian",ylab="segment type/token ratio (normalised)",xlab = paste0("segments of ",l.seg," words"),
# #                col=2)
# chars.n<-get_transformed_values(unlist(dta_t$chars.avg))
# a2m<-max(unlist(dta_t$chars.avg))+.001
# a2im<-max(chars.n)
# y<-max(a2im)/max(a2m)
# chars.n<-chars.n/y
# scatter.smooth(1:length(chars.n),chars.n,.1,.1,type="h",
#                family = "gaussian",ylab="segment average word length / chars (normalised)",xlab = paste0("segments of ",l.seg," words"),
#                col=2)
}#end plotfunction
dta_t<-plot.stats(src.h,"ttr",10,html.src = T)
View(dta_t)
dta_t<-plot.stats(src.h,"ttr",10,html.src = T)
source("~/Documents/GitHub/ETCRA5_dd23/R/scripts/plotstats_simple_static.R", echo=TRUE)
dta_t<-plot.stats(src.h,"char",10,html.src = T)
View(dta_t)
max(dta_t$chars.avg)
max(unlist(dta_t$chars.avg))
max(unlist(dta_t$chars.avg),na.rm = T)
which(max(unlist(dta_t$chars.avg),na.rm = T))
which.max(unlist(dta_t$chars.avg),na.rm = T)
which.max(unlist(dta_t$chars.avg))
source("~/Documents/GitHub/ETCRA5_dd23/R/scripts/plotstats_simple_static.R", echo=TRUE)
dta_t<-plot.stats(src.h,"ttr",10,html.src = T)
dta_t<-plot.stats(src.h,"char",10,html.src = T)
